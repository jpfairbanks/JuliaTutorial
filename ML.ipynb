{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Flux.jl\n",
    "\n",
    "Julia is a general purpose language that is easy to write and with fast numerics. No other language satisfies both of those design goals.\n",
    "\n",
    "Flux.jl is a machine learning library written in Julia.\n",
    "\n",
    "There is a Model Zoo: https://github.com/FluxML/model-zoo\n",
    "\n",
    "Flux runs of TPU: https://medium.com/syncedreview/google-cloud-tpus-now-speak-julia-cefd15a2a060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.add([\"Flux\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST MLP with Flux.jl\n",
    "\n",
    "MNIST hand written digits can be classified based on images with simple methods like Multlayer Perceptron (MLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/jpf/.julia/compiled/v1.0/Flux/QdkVy.ji for Flux [587475ba-b771-5e3f-ad9e-33799f191a9c]\n",
      "└ @ Base loading.jl:1184\n"
     ]
    }
   ],
   "source": [
    "using Flux, Flux.Data.MNIST, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated\n",
    "# using CuArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify MNIST digits with a simple multi-layer-perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784×60000 Array{Float64,2}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱            ⋮                      \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = MNIST.images()\n",
    "# Stack images into one large batch\n",
    "X = hcat(float.(reshape.(imgs, :))...) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×60000 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n",
       " false   true  false  false  false  …  false  false  false  false  false\n",
       " false  false  false   true  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false   true  false  false  false\n",
       " false  false   true  false  false     false  false  false  false  false\n",
       "  true  false  false  false  false  …  false  false   true  false  false\n",
       " false  false  false  false  false     false  false  false   true  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false      true  false  false  false   true\n",
       " false  false  false  false   true     false  false  false  false  false"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = MNIST.labels()\n",
    "# One-hot-encode the labels\n",
    "Y = onehotbatch(labels, 0:9) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(784, 32, NNlib.relu), Dense(32, 10), NNlib.softmax)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(\n",
    "  Dense(28^2, 32, relu),\n",
    "  Dense(32, 10),\n",
    "  softmax) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(784, 32, NNlib.relu), Dense(32, 10), NNlib.softmax)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Any,1}:\n",
       " Flux.Tracker.TrackedReal{Float64}[0.0199117 (tracked) 0.00191755 (tracked) … -0.0423476 (tracked) -0.0371253 (tracked); 0.0415548 (tracked) 0.0331267 (tracked) … -0.00308399 (tracked) 0.0646995 (tracked); … ; 0.00261522 (tracked) -0.0612279 (tracked) … -0.0293012 (tracked) -0.0276119 (tracked); 0.0450792 (tracked) 0.0725693 (tracked) … 0.0393874 (tracked) -0.0424292 (tracked)]\n",
       " Flux.Tracker.TrackedReal{Float64}[0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked)  …  0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked)]                                           \n",
       " Flux.Tracker.TrackedReal{Float64}[0.314871 (tracked) 0.274123 (tracked) … 0.017549 (tracked) -0.162626 (tracked); 0.0753589 (tracked) -0.127534 (tracked) … 0.263062 (tracked) -0.163508 (tracked); … ; -0.274863 (tracked) 0.20309 (tracked) … -0.0622504 (tracked) -0.0342836 (tracked); -0.0625383 (tracked) -0.246627 (tracked) … 0.168239 (tracked) -0.212878 (tracked)]              \n",
       " Flux.Tracker.TrackedReal{Float64}[0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked), 0.0 (tracked)]                                                                                                                                                                                                    "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#43 (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = crossentropy(m(x), y)\n",
    "\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "\n",
    "dataset = repeated((X, Y), 200)\n",
    "evalcb = () -> @show(loss(X, Y))\n",
    "opt = ADAM(params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X, Y) = 2.312386281511893 (tracked)\n",
      "loss(X, Y) = 1.5286909848020354 (tracked)\n",
      "loss(X, Y) = 0.9610744448267889 (tracked)\n",
      "loss(X, Y) = 0.6355869086998852 (tracked)\n",
      "loss(X, Y) = 0.5087488408718913 (tracked)\n",
      "loss(X, Y) = 0.42951634445743014 (tracked)\n",
      "loss(X, Y) = 0.38243854703592883 (tracked)\n",
      "loss(X, Y) = 0.3459428071944185 (tracked)\n",
      "loss(X, Y) = 0.3214095167352304 (tracked)\n",
      "loss(X, Y) = 0.2991887212550725 (tracked)\n",
      "loss(X, Y) = 0.28387892812728444 (tracked)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9258833333333333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flux.train!(loss, dataset, opt, cb = throttle(evalcb, 10))\n",
    "\n",
    "accuracy(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP convergence is monotonic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9265"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set accuracy\n",
    "tX = hcat(float.(reshape.(MNIST.images(:test), :))...) |> gpu\n",
    "tY = onehotbatch(MNIST.labels(:test), 0:9) |> gpu\n",
    "\n",
    "accuracy(tX, tY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP summary\n",
    "\n",
    "1. 92% accuracy is pretty good and would make a handwritten digit recognizer almost usable.\n",
    "2. 92.17% testing accuracy and 92.22% training accuracy means more training data will not improve the model much.\n",
    "3. This model is really simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×60000 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n",
       " false   true  false  false  false  …  false  false  false  false  false\n",
       " false  false  false   true  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false   true  false  false  false\n",
       " false  false   true  false  false     false  false  false  false  false\n",
       "  true  false  false  false  false  …  false  false   true  false  false\n",
       " false  false  false  false  false     false  false  false   true  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false      true  false  false  false   true\n",
       " false  false  false  false   true     false  false  false  false  false"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux, Flux.Data.MNIST, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "# using CuArrays\n",
    "\n",
    "# Classify MNIST digits with a convolutional network\n",
    "\n",
    "imgs = MNIST.images()\n",
    "\n",
    "labels = onehotbatch(MNIST.labels(), 0:9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}\n",
      "  height: Int64 10\n",
      "  data: Array{Flux.OneHotVector}((60000,))\n",
      "    1: Flux.OneHotVector\n",
      "      ix: UInt32 0x00000006\n",
      "      of: UInt32 0x0000000a\n",
      "    2: Flux.OneHotVector\n",
      "      ix: UInt32 0x00000001\n",
      "      of: UInt32 0x0000000a\n",
      "    3: Flux.OneHotVector\n",
      "      ix: UInt32 0x00000005\n",
      "      of: UInt32 0x0000000a\n",
      "    4: Flux.OneHotVector\n",
      "      ix: UInt32 0x00000002\n",
      "      of: UInt32 0x0000000a\n",
      "    5: Flux.OneHotVector\n",
      "      ix: UInt32 0x0000000a\n",
      "      of: UInt32 0x0000000a\n",
      "    ...\n",
      "    59996: Flux.OneHotVector\n",
      "      ix: UInt32 0x00000009\n",
      "      of: UInt32 0x0000000a\n",
      "    59997: Flux.OneHotVector\n",
      "      ix: UInt32 0x00000004\n",
      "      of: UInt32 0x0000000a\n",
      "    59998: Flux.OneHotVector\n",
      "      ix: UInt32 0x00000006\n",
      "      of: UInt32 0x0000000a\n",
      "    59999: Flux.OneHotVector\n",
      "      ix: UInt32 0x00000007\n",
      "      of: UInt32 0x0000000a\n",
      "    60000: Flux.OneHotVector\n",
      "      ix: UInt32 0x00000009\n",
      "      of: UInt32 0x0000000a\n"
     ]
    }
   ],
   "source": [
    "dump(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a OneHotMatrix?\n",
    "\n",
    "OneHotMatrix takes advantage of implicit data structures. You can store a \n",
    "\n",
    "```julia\n",
    "struct OneHotVector <: AbstractVector{Bool}\n",
    "  ix::UInt32\n",
    "  of::UInt32\n",
    "end\n",
    "\n",
    "Base.size(xs::OneHotVector) = (Int64(xs.of),)\n",
    "\n",
    "Base.getindex(xs::OneHotVector, i::Integer) = i == xs.ix\n",
    "\n",
    "A::AbstractMatrix * b::OneHotVector = A[:, b.ix]\n",
    "\n",
    "struct OneHotMatrix{A<:AbstractVector{OneHotVector}} <: AbstractMatrix{Bool}\n",
    "  height::Int\n",
    "  data::A\n",
    "end\n",
    "\n",
    "Base.size(xs::OneHotMatrix) = (Int64(xs.height),length(xs.data))\n",
    "\n",
    "Base.getindex(xs::OneHotMatrix, i::Integer, j::Integer) = xs.data[j][i]\n",
    "Base.getindex(xs::OneHotMatrix, ::Colon, i::Integer) = xs.data[i]\n",
    "Base.getindex(xs::OneHotMatrix, ::Colon, i::AbstractArray) = OneHotMatrix(xs.height, xs.data[i])\n",
    "\n",
    "A::AbstractMatrix * B::OneHotMatrix = A[:, map(x->x.ix, B.data)]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition into batches of size 1,000\n",
    "train = [(cat(float.(imgs[i])..., dims = 4), labels[:,i])\n",
    "         for i in partition(1:60_000, 1000)]\n",
    "\n",
    "train = gpu.(train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×1000 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n",
       " false  false  false   true  false  …  false  false   true  false  false\n",
       " false  false   true  false  false     false  false  false  false  false\n",
       " false   true  false  false  false      true   true  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false   true     false  false  false  false  false\n",
       " false  false  false  false  false  …  false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       "  true  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false   true  false\n",
       " false  false  false  false  false     false  false  false  false   true"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare test set (first 1,000 images)\n",
    "tX = cat(float.(MNIST.images(:test)[1:1000])..., dims = 4) |> gpu\n",
    "tY = onehotbatch(MNIST.labels(:test)[1:1000], 0:9) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 1=>16, NNlib.relu), getfield(Main, Symbol(\"##7#10\"))(), Conv((3, 3), 16=>10, NNlib.relu), getfield(Main, Symbol(\"##8#11\"))(), getfield(Main, Symbol(\"##9#12\"))(), Dense(250, 10), NNlib.softmax)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(\n",
    "  Conv((3,3), 1=>16, relu),\n",
    "  x -> maxpool(x, (2,2)),\n",
    "  Conv((3,3), 16=>10, relu),\n",
    "  x -> maxpool(x, (2,2)),\n",
    "  x -> reshape(x, :, size(x, 4)),\n",
    "  Dense(250, 10), softmax) |> gpu\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 10×1000 Array{Float64,2}:\n",
       " 0.0999303  0.099913   0.0998538  …  0.0997857  0.0999946  0.0997655\n",
       " 0.100447   0.100414   0.100206      0.100547   0.100413   0.100389 \n",
       " 0.0997646  0.0998514  0.099899      0.0997027  0.0998744  0.0998905\n",
       " 0.0997413  0.099776   0.0997121     0.0997578  0.0996898  0.0997585\n",
       " 0.100273   0.100215   0.100175      0.100169   0.100281   0.10028  \n",
       " 0.0999464  0.0999115  0.09995    …  0.0999775  0.0998559  0.0999404\n",
       " 0.0999679  0.0999881  0.100085      0.0999584  0.100095   0.0999822\n",
       " 0.0998387  0.0996606  0.100018      0.0997282  0.0997235  0.0997341\n",
       " 0.100175   0.10019    0.100081      0.100211   0.100107   0.100319 \n",
       " 0.0999167  0.100081   0.100021      0.100162   0.0999663  0.0999411"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(train[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#43 (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = crossentropy(m(x), y)\n",
    "\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "\n",
    "evalcb = throttle(() -> @show(accuracy(tX, tY)), 10)\n",
    "opt = AMSGrad(params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main /Users/jpf/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(tX, tY) = 0.164\n",
      "accuracy(tX, tY) = 0.435\n",
      "accuracy(tX, tY) = 0.799\n",
      "accuracy(tX, tY) = 0.851\n",
      "accuracy(tX, tY) = 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 2\n",
      "└ @ Main /Users/jpf/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(tX, tY) = 0.903\n",
      "accuracy(tX, tY) = 0.914\n",
      "accuracy(tX, tY) = 0.92\n",
      "accuracy(tX, tY) = 0.934\n",
      "accuracy(tX, tY) = 0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 3\n",
      "└ @ Main /Users/jpf/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(tX, tY) = 0.94\n",
      "accuracy(tX, tY) = 0.946\n",
      "accuracy(tX, tY) = 0.95\n",
      "accuracy(tX, tY) = 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 4\n",
      "└ @ Main /Users/jpf/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(tX, tY) = 0.955\n",
      "accuracy(tX, tY) = 0.951\n",
      "accuracy(tX, tY) = 0.955\n",
      "accuracy(tX, tY) = 0.953\n",
      "accuracy(tX, tY) = 0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 5\n",
      "└ @ Main /Users/jpf/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(tX, tY) = 0.959\n",
      "accuracy(tX, tY) = 0.954\n",
      "accuracy(tX, tY) = 0.956\n",
      "accuracy(tX, tY) = 0.954\n",
      "accuracy(tX, tY) = 0.956\n"
     ]
    }
   ],
   "source": [
    "Flux.@epochs 5 begin\n",
    "    Flux.train!(loss, train, opt, cb = evalcb)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go Deeper\n",
    "\n",
    "1. Training time is much longer\n",
    "2. Accuracy is better\n",
    "3. Code is almost just as simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Julia is the best language for ML\n",
    "1. Can write complex code in high level language\n",
    "2. No need to have C++ library under the hood\n",
    "3. Auto-diff / Backprop are being pioneered\n",
    "4. The same code can run on CPU/GPU\n",
    "5. Runs on TPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: Package Images not found in current path:\n- Run `Pkg.add(\"Images\")` to install the Images package.\n",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Package Images not found in current path:\n- Run `Pkg.add(\"Images\")` to install the Images package.\n",
      "",
      "Stacktrace:",
      " [1] require(::Module, ::Symbol) at ./loading.jl:817",
      " [2] top-level scope at In[19]:1"
     ]
    }
   ],
   "source": [
    "using Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
